{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQVH8ur4tcsV2t4qgB7RYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sei00f/python-scraping-kadai/blob/main/scraping_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6/2 リストをセットデータに\n",
        "!pip install selenium\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import MoveTargetOutOfBoundsException, NoSuchElementException\n",
        "\n",
        "# ヘッドレスモードで起動するためのオプションを設定\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument('--window-size=1920,1080')\n",
        "\n",
        "# スクレイピングの開始時間を記録\n",
        "start_time = time.time()\n",
        "\n",
        "# Chromeを立ち上げる\n",
        "chrome_driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# 日経新聞へアクセス\n",
        "chrome_driver.get('https://www.nikkei.com/markets/worldidx/chart/nk225/?type=６month')\n",
        "\n",
        "# 株価が表示されるまで待つ\n",
        "wait = WebDriverWait(chrome_driver, 30)\n",
        "wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'div.m-trend_chart_tab')))\n",
        "\n",
        "graph_element = chrome_driver.find_element(By.CSS_SELECTOR, 'rect.highcharts-background')\n",
        "\n",
        "def get_stock_values(chrome_driver, graph_element):\n",
        "    action = ActionChains(chrome_driver)\n",
        "    graph_width = graph_element.size['width']\n",
        "    graph_height = graph_element.size['height']\n",
        "\n",
        "    # グラフ中央にマウスを移動させる\n",
        "    try:\n",
        "        action.move_to_element(graph_element).perform()\n",
        "    except MoveTargetOutOfBoundsException as e:\n",
        "        print(f\"Error moving to center: {e}\")\n",
        "        return set()\n",
        "\n",
        "    stock_data = set()\n",
        "\n",
        "    # マウスをグラフの右端に移動させる\n",
        "    try:\n",
        "        action.move_by_offset(graph_width / 2, 0).perform()\n",
        "    except MoveTargetOutOfBoundsException as e:\n",
        "        print(f\"Error moving to right edge: {e}\")\n",
        "        return set()\n",
        "\n",
        "# HTMLから株価データを抽出する関数\n",
        "def extract_stock_data(stock_data):\n",
        "    soup = BeautifulSoup(chrome_driver.page_source, 'html.parser')\n",
        "    rows = soup.select('tbody tr')\n",
        "\n",
        "    for _ in range(int(graph_width)):  # グラフの幅の数だけループ\n",
        "        extract_stock_data(stock_data)\n",
        "        try:\n",
        "            # 1px左に移動\n",
        "            action = ActionChains(chrome_driver)\n",
        "            action.move_to_element_with_offset(graph_element, graph_width - _, graph_height / 2).perform()\n",
        "        except MoveTargetOutOfBoundsException as e:\n",
        "            print(f\"Error moving left by 1px: {e}\")\n",
        "            break\n",
        "        time.sleep(0.1)  # 少し待つことでデータが更新されるのを待つ\n",
        "\n",
        "    return stock_data\n",
        "\n",
        "    for row in rows:\n",
        "        td_elements = row.find_all('td')\n",
        "        if len(td_elements) < 5:\n",
        "            continue\n",
        "        # 日付のフォーマット変更\n",
        "        date_text = td_elements[0].text.strip()\n",
        "        # 文字列を日付オブジェクトに変換し、フォーマットを変更\n",
        "        date_obj = datetime.strptime(date_text, \"%Y/%m/%d\")\n",
        "        formatted_date = date_obj.strftime(\"%Y-%m-%d\")\n",
        "        open_price = td_elements[1].text.strip()\n",
        "        high_price = td_elements[2].text.strip()\n",
        "        low_price = td_elements[3].text.strip()\n",
        "        close_price = td_elements[4].text.strip()\n",
        "\n",
        "        stock_data.add((formatted_date, open_price, high_price, low_price, close_price))\n",
        "\n",
        "# 株価データを取得\n",
        "stock_data = get_stock_values(chrome_driver, graph_element)\n",
        "\n",
        "# スクレイピングの終了時間を記録\n",
        "end_time = time.time()\n",
        "\n",
        "# 結果を表示\n",
        "print(f\"スクレイピング時間: {end_time - start_time}秒\")\n",
        "if stock_data:\n",
        "    for data in stock_data:\n",
        "        print(data)\n",
        "else:\n",
        "    print(\"No stock data extracted.\")\n",
        "\n",
        "# Chromeを終了する\n",
        "chrome_driver.quit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZs08HidW6tM",
        "outputId": "c6f1f91d-d133-4212-d276-68fc91023f0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.21.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.25.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "スクレイピング時間: 4.883593559265137秒\n",
            "No stock data extracted.\n"
          ]
        }
      ]
    }
  ]
}